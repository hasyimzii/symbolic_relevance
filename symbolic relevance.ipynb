{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "# import nltk\n",
    "# nltk.download()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "pubmed = []\n",
    "\n",
    "# import pubmed\n",
    "docList = glob.glob(os.path.join(os.getcwd(), \"Datasets/pubmed/\", \"*.txt\"))\n",
    "\n",
    "for docPath in docList:\n",
    "    # get doc file name\n",
    "    docName = os.path.basename(docPath).split('.')[0]\n",
    "    \n",
    "    with open(docPath) as doc:\n",
    "        # insert [class, docs, feature]\n",
    "        pubmed.append([docName[:3], docName, doc.read().replace('\\n', ' ')])\n",
    "\n",
    "# print(pubmed)\n",
    "\n",
    "# make dataframe\n",
    "dataframe = pd.DataFrame(data=pubmed, columns=['class', 'document', 'feature']) \n",
    "\n",
    "# export pubmed raw\n",
    "dataframe.to_csv('pubmed/raw.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataframe raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv\n",
    "dataRaw = pd.read_csv('pubmed/raw.csv')\n",
    "# get feature\n",
    "features = dataRaw.loc[:, 'feature']\n",
    "dataRaw"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocesing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# cleaning\n",
    "def cleaning(features):\n",
    "    result = []\n",
    "    for feature in features:\n",
    "        regex = re.sub(r'[^a-zA-Z\\s]', '', feature)\n",
    "        result.append(regex)\n",
    "    return result\n",
    "\n",
    "# case folding\n",
    "def caseFolding(features):\n",
    "    result = []\n",
    "    for feature in features:\n",
    "        lower = feature.lower()\n",
    "        result.append(lower)\n",
    "    return result\n",
    "\n",
    "# tokenization\n",
    "def tokenization(features):\n",
    "    result = []\n",
    "    for feature in features:\n",
    "        token = word_tokenize(feature)\n",
    "        result.append(token)\n",
    "    return result\n",
    "\n",
    "# stopwords removal\n",
    "def stopWords(features):\n",
    "    result = []\n",
    "    stopWords = set(stopwords.words('english'))\n",
    "    for token in features:\n",
    "        cleanedFeature = [feature for feature in token if feature not in stopWords]\n",
    "        result.append(cleanedFeature)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "def preprocessing(features):\n",
    "    clean = cleaning(features)\n",
    "    case = caseFolding(clean)\n",
    "    token = tokenization(case)\n",
    "    preprocessed = stopWords(token)\n",
    "    \n",
    "preprocessed = preprocessing(features)\n",
    "# print(preprocessed)\n",
    "\n",
    "# export pubmed clean\n",
    "for i in range(len(preprocessed)):\n",
    "    dataRaw.loc[i, 'feature'] = ' '.join(preprocessed[i])\n",
    "dataRaw.to_csv('pubmed/clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv\n",
    "dataClean = pd.read_csv('pubmed/clean.csv')\n",
    "# get feature\n",
    "features = dataClean.loc[:, 'feature']\n",
    "dataClean"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Forming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "# BOAW\n",
    "dataClean.rename(columns={'feature': 'BOAW'}, inplace=True)\n",
    "\n",
    "for i in tqdm(range(len(features))):\n",
    "    # BON\n",
    "    dataClean.loc[i,'BON'] = ' '.join(TextBlob(features[i]).noun_phrases)\n",
    "    # BONA\n",
    "    dataClean.loc[i,'BONA'] = ' '.join([word for (word, tag) in TextBlob(features[i]).tags if tag[:2]=='NN' or tag[:2]=='JJ'])\n",
    "\n",
    "# print(dataClean)\n",
    "\n",
    "dataClean.to_csv('pubmed/formed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>document</th>\n",
       "      <th>BOAW</th>\n",
       "      <th>BON</th>\n",
       "      <th>BONA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALZ</td>\n",
       "      <td>ALZ1</td>\n",
       "      <td>reduced amounts immunoreactive somatostatin te...</td>\n",
       "      <td>amounts immunoreactive somatostatin temporal c...</td>\n",
       "      <td>reduced amounts immunoreactive somatostatin te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALZ</td>\n",
       "      <td>ALZ10</td>\n",
       "      <td>diagnostic criteria primary neuronal degenerat...</td>\n",
       "      <td>diagnostic criteria primary neuronal degenerat...</td>\n",
       "      <td>diagnostic criteria primary neuronal degenerat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALZ</td>\n",
       "      <td>ALZ100</td>\n",
       "      <td>cacetylcholine synthesis ccarbon dioxide produ...</td>\n",
       "      <td>cacetylcholine synthesis ccarbon dioxide produ...</td>\n",
       "      <td>cacetylcholine synthesis ccarbon dioxide produ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ALZ</td>\n",
       "      <td>ALZ1000</td>\n",
       "      <td>pattern reading deterioration dementia alzheim...</td>\n",
       "      <td>pattern reading deterioration dementia alzheim...</td>\n",
       "      <td>pattern deterioration dementia alzheimer type ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ALZ</td>\n",
       "      <td>ALZ101</td>\n",
       "      <td>cerebral blood flow metabolic rate oxygen gluc...</td>\n",
       "      <td>cerebral blood flow metabolic rate oxygen gluc...</td>\n",
       "      <td>cerebral blood flow metabolic rate oxygen gluc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>HIV</td>\n",
       "      <td>HIV3996</td>\n",
       "      <td>major histocompatibility complex genes influen...</td>\n",
       "      <td>major histocompatibility complex genes outcome...</td>\n",
       "      <td>major histocompatibility complex genes influen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>HIV</td>\n",
       "      <td>HIV3997</td>\n",
       "      <td>hiv infection cohort haemophilic patients cour...</td>\n",
       "      <td>hiv infection cohort haemophilic patients cour...</td>\n",
       "      <td>hiv infection cohort haemophilic patients cour...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>HIV</td>\n",
       "      <td>HIV3998</td>\n",
       "      <td>evolution definition aids main classifications...</td>\n",
       "      <td>evolution definition aids main classifications...</td>\n",
       "      <td>evolution definition aids main classifications...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>HIV</td>\n",
       "      <td>HIV3999</td>\n",
       "      <td>human immunodeficiency virus glycoproteins gp ...</td>\n",
       "      <td>human immunodeficiency virus glycoproteins gp ...</td>\n",
       "      <td>human immunodeficiency virus glycoproteins gp ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>HIV</td>\n",
       "      <td>HIV4000</td>\n",
       "      <td>predicting progression aids combined usefulnes...</td>\n",
       "      <td>progression aids usefulness cd lymphocyte coun...</td>\n",
       "      <td>progression aids usefulness cd lymphocyte p an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     class document                                               BOAW  \\\n",
       "0      ALZ     ALZ1  reduced amounts immunoreactive somatostatin te...   \n",
       "1      ALZ    ALZ10  diagnostic criteria primary neuronal degenerat...   \n",
       "2      ALZ   ALZ100  cacetylcholine synthesis ccarbon dioxide produ...   \n",
       "3      ALZ  ALZ1000  pattern reading deterioration dementia alzheim...   \n",
       "4      ALZ   ALZ101  cerebral blood flow metabolic rate oxygen gluc...   \n",
       "...    ...      ...                                                ...   \n",
       "3995   HIV  HIV3996  major histocompatibility complex genes influen...   \n",
       "3996   HIV  HIV3997  hiv infection cohort haemophilic patients cour...   \n",
       "3997   HIV  HIV3998  evolution definition aids main classifications...   \n",
       "3998   HIV  HIV3999  human immunodeficiency virus glycoproteins gp ...   \n",
       "3999   HIV  HIV4000  predicting progression aids combined usefulnes...   \n",
       "\n",
       "                                                    BON  \\\n",
       "0     amounts immunoreactive somatostatin temporal c...   \n",
       "1     diagnostic criteria primary neuronal degenerat...   \n",
       "2     cacetylcholine synthesis ccarbon dioxide produ...   \n",
       "3     pattern reading deterioration dementia alzheim...   \n",
       "4     cerebral blood flow metabolic rate oxygen gluc...   \n",
       "...                                                 ...   \n",
       "3995  major histocompatibility complex genes outcome...   \n",
       "3996  hiv infection cohort haemophilic patients cour...   \n",
       "3997  evolution definition aids main classifications...   \n",
       "3998  human immunodeficiency virus glycoproteins gp ...   \n",
       "3999  progression aids usefulness cd lymphocyte coun...   \n",
       "\n",
       "                                                   BONA  \n",
       "0     reduced amounts immunoreactive somatostatin te...  \n",
       "1     diagnostic criteria primary neuronal degenerat...  \n",
       "2     cacetylcholine synthesis ccarbon dioxide produ...  \n",
       "3     pattern deterioration dementia alzheimer type ...  \n",
       "4     cerebral blood flow metabolic rate oxygen gluc...  \n",
       "...                                                 ...  \n",
       "3995  major histocompatibility complex genes influen...  \n",
       "3996  hiv infection cohort haemophilic patients cour...  \n",
       "3997  evolution definition aids main classifications...  \n",
       "3998  human immunodeficiency virus glycoproteins gp ...  \n",
       "3999  progression aids usefulness cd lymphocyte p an...  \n",
       "\n",
       "[4000 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read csv\n",
    "dataFormed = pd.read_csv('pubmed/formed.csv')\n",
    "# get features\n",
    "classes = dataFormed.loc[:, 'class']\n",
    "boaw = dataFormed.loc[:, 'BOAW']\n",
    "bon = dataFormed.loc[:, 'BON']\n",
    "bona = dataFormed.loc[:, 'BONA']\n",
    "dataFormed"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Term Weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# TF\n",
    "def tf(features):\n",
    "    # get tf weights\n",
    "    tfVec = CountVectorizer()\n",
    "    result = tfVec.fit_transform(features)\n",
    "\n",
    "    # define weights into dataframe\n",
    "    featureName = tfVec.get_feature_names_out()\n",
    "    featureWeight = result.todense().tolist()\n",
    "    df = pd.DataFrame(featureWeight, columns=featureName)\n",
    "    return df\n",
    "\n",
    "    # # counting weights into dictionary\n",
    "    # tf = dict.fromkeys(featureName, 0)\n",
    "    # for word in tqdm(featureName):\n",
    "    #     arr = np.array(df.loc[:, word])\n",
    "    #     val = np.sum(arr)\n",
    "    #     tf[word] = val\n",
    "    # return tf\n",
    "\n",
    "# tfx = tf(bona)\n",
    "# print(tfx)\n",
    "\n",
    "# TF-IDF\n",
    "def tf_idf(features):\n",
    "    # get tf-idf weights\n",
    "    tfIdfVec = TfidfVectorizer()\n",
    "    result = tfIdfVec.fit_transform(features)\n",
    "\n",
    "    # define weights into dataframe\n",
    "    featureName = tfIdfVec.get_feature_names_out()\n",
    "    featureWeight = result.todense().tolist()\n",
    "    df = pd.DataFrame(featureWeight, columns=featureName)\n",
    "    return df\n",
    "    \n",
    "    # # counting weights into dictionary\n",
    "    # tfIdf = dict.fromkeys(featureName, 0)\n",
    "    # for word in tqdm(featureName):\n",
    "    #     arr = np.array(df.loc[:, word])\n",
    "    #     val = np.sum(arr)\n",
    "    #     tfIdf[word] = val\n",
    "    # return tfIdf\n",
    "\n",
    "# idfx = tf_idf(bona)\n",
    "# print(idfx)\n",
    "\n",
    "# TF-IDF-ICF\n",
    "def icf(word, features):\n",
    "    classTotal = []\n",
    "    classTerm = []\n",
    "\n",
    "    # count class \n",
    "    for i in classes:\n",
    "        if i not in classTotal:\n",
    "            classTotal.append(i)\n",
    "\n",
    "    # count class term\n",
    "    for i in range(len(features)):\n",
    "        if word in features[i]:\n",
    "            if classes[i] not in classTerm:\n",
    "                classTerm.append(classes[i])\n",
    "  \n",
    "    # count icf\n",
    "    icf = math.log(len(classTotal) / float(len(classTerm)))\n",
    "    return icf\n",
    "\n",
    "def tf_idf_icf(features):\n",
    "    # count tf-idf\n",
    "    df = tf_idf(features)\n",
    "\n",
    "    for col in tqdm(df.columns):\n",
    "        icfResult = icf(col, features)\n",
    "        for row in df.iterrows():\n",
    "            df.loc[row[0], col] = df.loc[row[0], col] * icfResult\n",
    "    return df\n",
    "\n",
    "    # # counting weights into dictionary\n",
    "    # tfIdfIcf = dict.fromkeys(list(tfIdf.keys()), 0)\n",
    "    # for word, val in tqdm(tfIdf.items()):\n",
    "    #     tfIdfIcf[word] = val * icf(word, features)\n",
    "    # return tfIdfIcf\n",
    "\n",
    "# icfx = tf_idf_icf(bona)\n",
    "# print(icfx)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:00<00:00, 242.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        and  computer  education  finance        in  information  logistic  \\\n",
      "0  0.000000  0.000000   0.000000        2  0.000000     2.584963  0.000000   \n",
      "1  0.000000  0.000000   0.000000        2  0.000000     2.584963  0.000000   \n",
      "2  0.000000  0.000000   0.000000        0  0.000000     2.584963  1.584963   \n",
      "3  0.000000  0.000000   0.000000        0  0.000000     2.584963  0.000000   \n",
      "4  0.000000  1.584963   1.584963        0  1.169925     0.000000  0.000000   \n",
      "5  1.584963  1.584963   0.000000        0  0.000000     0.000000  0.000000   \n",
      "\n",
      "   management   medical    school    system class  \n",
      "0    1.321928  0.000000  0.000000  4.000000     A  \n",
      "1    0.000000  0.000000  0.000000  4.000000     A  \n",
      "2    0.000000  0.000000  0.000000  2.000000     A  \n",
      "3    0.000000  1.584963  0.000000  2.000000     A  \n",
      "4    1.321928  0.000000  1.584963  1.137504     B  \n",
      "5    1.321928  0.000000  0.000000  1.137504     C  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# from textvec.vectorizers import TfrfVectorizer\n",
    "\n",
    "# TF-RF\n",
    "# tfRfVec = TfrfVectorizer()\n",
    "# tfRfVec.fit()\n",
    "\n",
    "def rf(word, features, wordClass):\n",
    "    positive = 0\n",
    "    negative = 0\n",
    "\n",
    "    for i in range(len(features)):\n",
    "        if word in features[i]:\n",
    "            # count docs contain term in class C\n",
    "            if classes[i] == wordClass:\n",
    "                positive += 1\n",
    "            # count docs contain term not in class C\n",
    "            else :\n",
    "                negative += 1\n",
    "    \n",
    "    # count rf\n",
    "    rf = math.log2(2 + (positive / np.maximum(1, negative)))\n",
    "    return rf\n",
    "\n",
    "def tf_rf(features):\n",
    "    # count tf\n",
    "    df = tf(features)\n",
    "\n",
    "    for col in tqdm(df.columns):\n",
    "        for row in df.iterrows():\n",
    "            rfResult = rf(col, features, classes[row[0]])\n",
    "            df.loc[row[0], col] = df.loc[row[0], col] * rfResult\n",
    "    return df\n",
    "\n",
    "    # tfRf = dict.fromkeys(list(tf.keys()), 0)\n",
    "    # for word, val in tqdm(tf.items()):\n",
    "    #     tfRf[word] = val * rf(word, features)\n",
    "    # return tfRf\n",
    "\n",
    "classes = ['A', 'A', 'A', 'A', 'B', 'C']\n",
    "data = ['system system information management finance', 'system system information finance', 'system information logistic', 'medical information system', 'system computer education in management school', 'system computer and management']\n",
    "\n",
    "rfx = tf_rf(data)\n",
    "rfx.loc[:, 'class'] = classes\n",
    "print(rfx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>computer</th>\n",
       "      <th>education</th>\n",
       "      <th>finance</th>\n",
       "      <th>in</th>\n",
       "      <th>information</th>\n",
       "      <th>logistic</th>\n",
       "      <th>management</th>\n",
       "      <th>medical</th>\n",
       "      <th>school</th>\n",
       "      <th>system</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.584963</td>\n",
       "      <td>0.396241</td>\n",
       "      <td>0.330482</td>\n",
       "      <td>0.396241</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.584963</td>\n",
       "      <td>1.584963</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.169925</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.321928</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.584963</td>\n",
       "      <td>1.137504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>1.584963</td>\n",
       "      <td>1.584963</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.321928</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.137504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            and  computer  education  finance        in  information  \\\n",
       "class                                                                  \n",
       "A      0.000000  0.000000   0.000000      1.0  0.000000     2.584963   \n",
       "B      0.000000  1.584963   1.584963      0.0  1.169925     0.000000   \n",
       "C      1.584963  1.584963   0.000000      0.0  0.000000     0.000000   \n",
       "\n",
       "       logistic  management   medical    school    system  \n",
       "class                                                      \n",
       "A      0.396241    0.330482  0.396241  0.000000  3.000000  \n",
       "B      0.000000    1.321928  0.000000  1.584963  1.137504  \n",
       "C      0.000000    1.321928  0.000000  0.000000  1.137504  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = rfx.groupby('class').mean()\n",
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "and            1.584963\n",
       "computer       1.584963\n",
       "education      1.584963\n",
       "finance        1.000000\n",
       "in             1.169925\n",
       "information    2.584963\n",
       "logistic       0.396241\n",
       "management     1.321928\n",
       "medical        0.396241\n",
       "school         1.584963\n",
       "system         3.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff = mean.max()\n",
    "diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "and            1.000000\n",
       "computer       2.000000\n",
       "education      1.000000\n",
       "finance        1.000000\n",
       "in             1.000000\n",
       "information    1.000000\n",
       "logistic       1.000000\n",
       "management     2.250000\n",
       "medical        1.000000\n",
       "school         1.000000\n",
       "system         1.758336\n",
       "dtype: float64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(mean/diff).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfx.to_csv('rfrf.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from spherecluster import SphericalKMeans\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# K-Means++\n",
    "# kmp = KMeans(n_clusters=n)\n",
    "\n",
    "# Spherical K-Means\n",
    "# skm = SphericalKMeans(n_clusters=n)\n",
    "# skm.fit(X)\n",
    "\n",
    "# skm.cluster_centers_\n",
    "# skm.labels_\n",
    "# skm.inertia_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics.cluster import contingency_matrix\n",
    "from sklearn.metrics import adjusted_mutual_info_score\n",
    "\n",
    "# Silhouette Score\n",
    "# silhouette_score(labels_true, labels_pred)\n",
    "\n",
    "# Purity\n",
    "# contingency_matrix(labels_true, labels_pred)\n",
    "\n",
    "# AMI\n",
    "# adjusted_mutual_info_score(labels_true, labels_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ab696253bf1cbd9262a120019f89a6af5e719602af9132e0a92b18d085125844"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
