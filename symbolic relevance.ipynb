{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "# import nltk\n",
    "# nltk.download()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "pubmed = []\n",
    "\n",
    "# import pubmed\n",
    "docList = glob.glob(os.path.join(os.getcwd(), \"Datasets/pubmed/\", \"*.txt\"))\n",
    "\n",
    "for docPath in docList:\n",
    "    # get doc file name\n",
    "    docName = os.path.basename(docPath).split('.')[0]\n",
    "    \n",
    "    with open(docPath) as doc:\n",
    "        # insert [class, docs, feature]\n",
    "        pubmed.append([docName[:3], docName, doc.read().replace('\\n', ' ')])\n",
    "\n",
    "# print(pubmed)\n",
    "\n",
    "# make dataframe\n",
    "dataframe = pd.DataFrame(data=pubmed, columns=['class', 'document', 'feature']) \n",
    "\n",
    "# export pubmed raw\n",
    "dataframe.to_csv('pubmed/raw.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataframe raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv\n",
    "dataRaw = pd.read_csv('pubmed/raw.csv')\n",
    "# get feature\n",
    "features = dataRaw.loc[:, 'feature']\n",
    "dataRaw"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocesing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# cleaning\n",
    "def cleaning(features):\n",
    "    result = []\n",
    "    for feature in features:\n",
    "        regex = re.sub(r'[^a-zA-Z\\s]', '', feature)\n",
    "        result.append(regex)\n",
    "    return result\n",
    "\n",
    "# case folding\n",
    "def caseFolding(features):\n",
    "    result = []\n",
    "    for feature in features:\n",
    "        lower = feature.lower()\n",
    "        result.append(lower)\n",
    "    return result\n",
    "\n",
    "# tokenization\n",
    "def tokenization(features):\n",
    "    result = []\n",
    "    for feature in features:\n",
    "        token = word_tokenize(feature)\n",
    "        result.append(token)\n",
    "    return result\n",
    "\n",
    "# stopwords removal\n",
    "def stopWords(features):\n",
    "    result = []\n",
    "    stopWords = set(stopwords.words('english'))\n",
    "    for token in features:\n",
    "        cleanedFeature = [feature for feature in token if feature not in stopWords]\n",
    "        result.append(cleanedFeature)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "def preprocessing(features):\n",
    "    clean = cleaning(features)\n",
    "    case = caseFolding(clean)\n",
    "    token = tokenization(case)\n",
    "    preprocessed = stopWords(token)\n",
    "    \n",
    "preprocessed = preprocessing(features)\n",
    "# print(preprocessed)\n",
    "\n",
    "# export pubmed clean\n",
    "for i in range(len(preprocessed)):\n",
    "    dataRaw.loc[i, 'feature'] = ' '.join(preprocessed[i])\n",
    "dataRaw.to_csv('pubmed/clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv\n",
    "dataClean = pd.read_csv('pubmed/clean.csv')\n",
    "# get feature\n",
    "features = dataClean.loc[:, 'feature']\n",
    "dataClean"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Forming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "# BOAW\n",
    "dataClean.rename(columns={'feature': 'BOAW'}, inplace=True)\n",
    "\n",
    "for i in tqdm(range(len(features))):\n",
    "    # BON\n",
    "    dataClean.loc[i, 'BON'] = ' '.join(TextBlob(features[i]).noun_phrases)\n",
    "    # BONA\n",
    "    dataClean.loc[i, 'BONA'] = ' '.join([word for (word, tag) in TextBlob(features[i]).tags if tag[:2]=='NN' or tag[:2]=='JJ'])\n",
    "\n",
    "# print(dataClean)\n",
    "\n",
    "dataClean.to_csv('pubmed/formed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>document</th>\n",
       "      <th>BOAW</th>\n",
       "      <th>BON</th>\n",
       "      <th>BONA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALZ</td>\n",
       "      <td>ALZ1</td>\n",
       "      <td>reduced amounts immunoreactive somatostatin te...</td>\n",
       "      <td>amounts immunoreactive somatostatin temporal c...</td>\n",
       "      <td>reduced amounts immunoreactive somatostatin te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALZ</td>\n",
       "      <td>ALZ10</td>\n",
       "      <td>diagnostic criteria primary neuronal degenerat...</td>\n",
       "      <td>diagnostic criteria primary neuronal degenerat...</td>\n",
       "      <td>diagnostic criteria primary neuronal degenerat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALZ</td>\n",
       "      <td>ALZ100</td>\n",
       "      <td>cacetylcholine synthesis ccarbon dioxide produ...</td>\n",
       "      <td>cacetylcholine synthesis ccarbon dioxide produ...</td>\n",
       "      <td>cacetylcholine synthesis ccarbon dioxide produ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ALZ</td>\n",
       "      <td>ALZ1000</td>\n",
       "      <td>pattern reading deterioration dementia alzheim...</td>\n",
       "      <td>pattern reading deterioration dementia alzheim...</td>\n",
       "      <td>pattern deterioration dementia alzheimer type ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ALZ</td>\n",
       "      <td>ALZ101</td>\n",
       "      <td>cerebral blood flow metabolic rate oxygen gluc...</td>\n",
       "      <td>cerebral blood flow metabolic rate oxygen gluc...</td>\n",
       "      <td>cerebral blood flow metabolic rate oxygen gluc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>HIV</td>\n",
       "      <td>HIV3996</td>\n",
       "      <td>major histocompatibility complex genes influen...</td>\n",
       "      <td>major histocompatibility complex genes outcome...</td>\n",
       "      <td>major histocompatibility complex genes influen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>HIV</td>\n",
       "      <td>HIV3997</td>\n",
       "      <td>hiv infection cohort haemophilic patients cour...</td>\n",
       "      <td>hiv infection cohort haemophilic patients cour...</td>\n",
       "      <td>hiv infection cohort haemophilic patients cour...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>HIV</td>\n",
       "      <td>HIV3998</td>\n",
       "      <td>evolution definition aids main classifications...</td>\n",
       "      <td>evolution definition aids main classifications...</td>\n",
       "      <td>evolution definition aids main classifications...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>HIV</td>\n",
       "      <td>HIV3999</td>\n",
       "      <td>human immunodeficiency virus glycoproteins gp ...</td>\n",
       "      <td>human immunodeficiency virus glycoproteins gp ...</td>\n",
       "      <td>human immunodeficiency virus glycoproteins gp ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>HIV</td>\n",
       "      <td>HIV4000</td>\n",
       "      <td>predicting progression aids combined usefulnes...</td>\n",
       "      <td>progression aids usefulness cd lymphocyte coun...</td>\n",
       "      <td>progression aids usefulness cd lymphocyte p an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     class document                                               BOAW  \\\n",
       "0      ALZ     ALZ1  reduced amounts immunoreactive somatostatin te...   \n",
       "1      ALZ    ALZ10  diagnostic criteria primary neuronal degenerat...   \n",
       "2      ALZ   ALZ100  cacetylcholine synthesis ccarbon dioxide produ...   \n",
       "3      ALZ  ALZ1000  pattern reading deterioration dementia alzheim...   \n",
       "4      ALZ   ALZ101  cerebral blood flow metabolic rate oxygen gluc...   \n",
       "...    ...      ...                                                ...   \n",
       "3995   HIV  HIV3996  major histocompatibility complex genes influen...   \n",
       "3996   HIV  HIV3997  hiv infection cohort haemophilic patients cour...   \n",
       "3997   HIV  HIV3998  evolution definition aids main classifications...   \n",
       "3998   HIV  HIV3999  human immunodeficiency virus glycoproteins gp ...   \n",
       "3999   HIV  HIV4000  predicting progression aids combined usefulnes...   \n",
       "\n",
       "                                                    BON  \\\n",
       "0     amounts immunoreactive somatostatin temporal c...   \n",
       "1     diagnostic criteria primary neuronal degenerat...   \n",
       "2     cacetylcholine synthesis ccarbon dioxide produ...   \n",
       "3     pattern reading deterioration dementia alzheim...   \n",
       "4     cerebral blood flow metabolic rate oxygen gluc...   \n",
       "...                                                 ...   \n",
       "3995  major histocompatibility complex genes outcome...   \n",
       "3996  hiv infection cohort haemophilic patients cour...   \n",
       "3997  evolution definition aids main classifications...   \n",
       "3998  human immunodeficiency virus glycoproteins gp ...   \n",
       "3999  progression aids usefulness cd lymphocyte coun...   \n",
       "\n",
       "                                                   BONA  \n",
       "0     reduced amounts immunoreactive somatostatin te...  \n",
       "1     diagnostic criteria primary neuronal degenerat...  \n",
       "2     cacetylcholine synthesis ccarbon dioxide produ...  \n",
       "3     pattern deterioration dementia alzheimer type ...  \n",
       "4     cerebral blood flow metabolic rate oxygen gluc...  \n",
       "...                                                 ...  \n",
       "3995  major histocompatibility complex genes influen...  \n",
       "3996  hiv infection cohort haemophilic patients cour...  \n",
       "3997  evolution definition aids main classifications...  \n",
       "3998  human immunodeficiency virus glycoproteins gp ...  \n",
       "3999  progression aids usefulness cd lymphocyte p an...  \n",
       "\n",
       "[4000 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read csv\n",
    "dataFormed = pd.read_csv('pubmed/formed.csv')\n",
    "# get features\n",
    "classes = dataFormed.loc[:, 'class']\n",
    "boaw = dataFormed.loc[:, 'BOAW']\n",
    "bon = dataFormed.loc[:, 'BON']\n",
    "bona = dataFormed.loc[:, 'BONA']\n",
    "dataFormed"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aa               1.666667\n",
      "aab              1.000000\n",
      "aabc             1.000000\n",
      "aac              1.000000\n",
      "aaf              1.600000\n",
      "                   ...   \n",
      "zygomycosis      1.000000\n",
      "zygotic          1.000000\n",
      "zymosan          1.000000\n",
      "zypab            1.000000\n",
      "zytologisches    1.000000\n",
      "Length: 18357, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from scipy.sparse import spdiags\n",
    "\n",
    "# TF-RF\n",
    "def tf_rf(features, classes):\n",
    "    # get tf weights\n",
    "    tfVec = CountVectorizer()\n",
    "    tf = tfVec.fit_transform(features)\n",
    "\n",
    "    # get classes weights\n",
    "    clsVec = LabelBinarizer()\n",
    "    cls = clsVec.fit_transform(classes)\n",
    "\n",
    "    if cls.shape[1] == 1:\n",
    "        cls = np.append(1 - cls, cls, axis=1)\n",
    "\n",
    "    # count rf\n",
    "    feature = ((cls.T * tf) > 0).astype(np.float64)\n",
    "\n",
    "    for i in range(cls.shape[1]):\n",
    "        # feature.sum(axis=0) - feature[i] is the sum of all rows except i\n",
    "        feature[i] /= np.maximum(1., feature.sum(axis=0) - feature[i])\n",
    "\n",
    "    rf = np.mean(np.log2(2 + feature, out=feature), axis=0)\n",
    "\n",
    "    # count tf-rf & transform\n",
    "    n_features = rf.shape[0]\n",
    "    tfRf = tf * spdiags(rf, 0, n_features, n_features)\n",
    "\n",
    "    # define weights into dataframe\n",
    "    featureName = tfVec.get_feature_names_out()\n",
    "    featureWeight = tfRf.todense()\n",
    "    df = pd.DataFrame(featureWeight, columns=featureName)\n",
    "    df.loc[:, 'class'] = classes\n",
    "    # return df\n",
    "\n",
    "    # count weight by class\n",
    "    mean = df.groupby('class').mean()\n",
    "    result = (mean/mean.max()).sum()\n",
    "    print(result)\n",
    "\n",
    "    # select minimum weighted features\n",
    "    # selected = []\n",
    "    # for i in range(len(result)):\n",
    "    #     if result[i] != 0 and result[i] == np.min(result):\n",
    "    #         selected.append(df.columns[i])\n",
    "    # return selected\n",
    "\n",
    "rfx = tf_rf(bona, classes)\n",
    "# print(rfx)\n",
    "\n",
    "def symbolic_relevance(features, classes):\n",
    "    # get sfs\n",
    "    # sfs = sfs(features)\n",
    "\n",
    "    # get tf-rf\n",
    "    tfrf = tf_rf(features, classes)\n",
    "\n",
    "    # intersect features\n",
    "    selected = [word for word in sfs if word in tfrf]\n",
    "\n",
    "    # update features\n",
    "    token = tokenization(features)\n",
    "    result = []\n",
    "    for row in tqdm(token):\n",
    "        words = [word for word in row if word in selected]\n",
    "        result.append(words)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BONA > SR\n",
    "# bona_sr = symbolic_relevance(bona, classes)\n",
    "bona_sr = tf_rf(bona, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save csv\n",
    "for i in range(len(dataFormed)):\n",
    "    # BOAW\n",
    "    # dataFormed.loc[i, 'BOAW_SR'] = ' '.join(boaw_sr[i])\n",
    "    # BON\n",
    "    # dataFormed.loc[i, 'BON_SR'] = ' '.join(bon_sr[i])\n",
    "    # BONA\n",
    "    dataFormed.loc[i, 'BONA_SR'] = ' '.join(bona_sr[i])\n",
    "\n",
    "dataFormed.to_csv('pubmed/selected.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>document</th>\n",
       "      <th>BONA_TFRF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALZ</td>\n",
       "      <td>ALZ1</td>\n",
       "      <td>immunoreactive somatostatin senile dementia po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALZ</td>\n",
       "      <td>ALZ10</td>\n",
       "      <td>diagnostic primary degeneration alzheimers att...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALZ</td>\n",
       "      <td>ALZ100</td>\n",
       "      <td>cacetylcholine synthesis ccarbon prisms human ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ALZ</td>\n",
       "      <td>ALZ1000</td>\n",
       "      <td>deterioration dementia observations implicatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ALZ</td>\n",
       "      <td>ALZ101</td>\n",
       "      <td>flow metabolic oxygen glucose lactate pyruvate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>HIV</td>\n",
       "      <td>HIV3996</td>\n",
       "      <td>histocompatibility hiv infection ancestral hap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>HIV</td>\n",
       "      <td>HIV3997</td>\n",
       "      <td>hiv infection haemophilic hiv infection haemop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>HIV</td>\n",
       "      <td>HIV3998</td>\n",
       "      <td>evolution aids infection evolution aids hiv in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>HIV</td>\n",
       "      <td>HIV3999</td>\n",
       "      <td>human immunodeficiency glycoproteins gp cdt re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>HIV</td>\n",
       "      <td>HIV4000</td>\n",
       "      <td>aids antigenemia human immunodeficiency hiv im...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     class document                                          BONA_TFRF\n",
       "0      ALZ     ALZ1  immunoreactive somatostatin senile dementia po...\n",
       "1      ALZ    ALZ10  diagnostic primary degeneration alzheimers att...\n",
       "2      ALZ   ALZ100  cacetylcholine synthesis ccarbon prisms human ...\n",
       "3      ALZ  ALZ1000  deterioration dementia observations implicatio...\n",
       "4      ALZ   ALZ101  flow metabolic oxygen glucose lactate pyruvate...\n",
       "...    ...      ...                                                ...\n",
       "3995   HIV  HIV3996  histocompatibility hiv infection ancestral hap...\n",
       "3996   HIV  HIV3997  hiv infection haemophilic hiv infection haemop...\n",
       "3997   HIV  HIV3998  evolution aids infection evolution aids hiv in...\n",
       "3998   HIV  HIV3999  human immunodeficiency glycoproteins gp cdt re...\n",
       "3999   HIV  HIV4000  aids antigenemia human immunodeficiency hiv im...\n",
       "\n",
       "[4000 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read csv\n",
    "dataSelected = pd.read_csv('pubmed/selected.csv')\n",
    "# get features\n",
    "classes = dataSelected.loc[:, 'class']\n",
    "# bona_sr = dataSelected.loc[:, 'BONA_SR']\n",
    "bona_sr = dataSelected.loc[:, 'BONA_TFRF']\n",
    "dataSelected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Term Weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# TF\n",
    "def tf(features):\n",
    "    # get tf weights\n",
    "    tfVec = CountVectorizer()\n",
    "    result = tfVec.fit_transform(features)\n",
    "\n",
    "    # define weights into dataframe\n",
    "    featureName = tfVec.get_feature_names_out()\n",
    "    featureWeight = result.todense()\n",
    "    df = pd.DataFrame(featureWeight, columns=featureName)\n",
    "    return df\n",
    "\n",
    "    # # counting weights into dictionary\n",
    "    # tf = dict.fromkeys(featureName, 0)\n",
    "    # for word in tqdm(featureName):\n",
    "    #     arr = np.array(df.loc[:, word])\n",
    "    #     val = np.sum(arr)\n",
    "    #     tf[word] = val\n",
    "    # return tf\n",
    "\n",
    "# tfx = tf(bona)\n",
    "# print(tfx)\n",
    "\n",
    "# TF-IDF\n",
    "def tf_idf(features):\n",
    "    # get tf-idf weights\n",
    "    tfIdfVec = TfidfVectorizer()\n",
    "    result = tfIdfVec.fit_transform(features)\n",
    "\n",
    "    # define weights into dataframe\n",
    "    featureName = tfIdfVec.get_feature_names_out()\n",
    "    featureWeight = result.todense()\n",
    "    df = pd.DataFrame(featureWeight, columns=featureName)\n",
    "    return df\n",
    "    \n",
    "    # # counting weights into dictionary\n",
    "    # tfIdf = dict.fromkeys(featureName, 0)\n",
    "    # for word in tqdm(featureName):\n",
    "    #     arr = np.array(df.loc[:, word])\n",
    "    #     val = np.sum(arr)\n",
    "    #     tfIdf[word] = val\n",
    "    # return tfIdf\n",
    "\n",
    "# idfx = tf_idf(bona)\n",
    "# print(idfx)\n",
    "\n",
    "# TF-IDF-ICF\n",
    "def icf(word, features, classes):\n",
    "    classTotal = []\n",
    "    classTerm = []\n",
    "\n",
    "    for i in range(len(classes)):\n",
    "        # count class \n",
    "        if classes[i] not in classTotal:\n",
    "            classTotal.append(i)\n",
    "\n",
    "            # count class term\n",
    "            if word in features[i]:\n",
    "                if classes[i] not in classTerm:\n",
    "                    classTerm.append(classes[i])\n",
    "  \n",
    "    # count icf\n",
    "    icf = 1 + math.log(len(classTotal) / float(len(classTerm)))\n",
    "    return icf\n",
    "\n",
    "def tf_idf_icf(features, classes):\n",
    "    # count tf-idf\n",
    "    df = tf_idf(features)\n",
    "\n",
    "    for col in tqdm(df.columns):\n",
    "        icfResult = icf(col, features, classes)\n",
    "        for row in range(len(features)):\n",
    "            df.loc[row, col] = df.loc[row, col] * icfResult\n",
    "    return df\n",
    "\n",
    "    # # counting weights into dictionary\n",
    "    # tfIdfIcf = dict.fromkeys(list(tfIdf.keys()), 0)\n",
    "    # for word, val in tqdm(tfIdf.items()):\n",
    "    #     tfIdfIcf[word] = val * icf(word, features)\n",
    "    # return tfIdfIcf\n",
    "\n",
    "# icfx = tf_idf_icf(bona, classes)\n",
    "# print(icfx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aab</th>\n",
       "      <th>aabc</th>\n",
       "      <th>aac</th>\n",
       "      <th>aagarose</th>\n",
       "      <th>abbott</th>\n",
       "      <th>abbreviation</th>\n",
       "      <th>abc</th>\n",
       "      <th>abdomen</th>\n",
       "      <th>abdominoperineal</th>\n",
       "      <th>abe</th>\n",
       "      <th>...</th>\n",
       "      <th>zoster</th>\n",
       "      <th>zovirax</th>\n",
       "      <th>zucker</th>\n",
       "      <th>zurich</th>\n",
       "      <th>zygomycete</th>\n",
       "      <th>zygomycetes</th>\n",
       "      <th>zygomycosis</th>\n",
       "      <th>zygotic</th>\n",
       "      <th>zymosan</th>\n",
       "      <th>zypab</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 11291 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      aab  aabc  aac  aagarose  abbott  abbreviation  abc  abdomen  \\\n",
       "0     0.0   0.0  0.0       0.0     0.0           0.0  0.0      0.0   \n",
       "1     0.0   0.0  0.0       0.0     0.0           0.0  0.0      0.0   \n",
       "2     0.0   0.0  0.0       0.0     0.0           0.0  0.0      0.0   \n",
       "3     0.0   0.0  0.0       0.0     0.0           0.0  0.0      0.0   \n",
       "4     0.0   0.0  0.0       0.0     0.0           0.0  0.0      0.0   \n",
       "...   ...   ...  ...       ...     ...           ...  ...      ...   \n",
       "3995  0.0   0.0  0.0       0.0     0.0           0.0  0.0      0.0   \n",
       "3996  0.0   0.0  0.0       0.0     0.0           0.0  0.0      0.0   \n",
       "3997  0.0   0.0  0.0       0.0     0.0           0.0  0.0      0.0   \n",
       "3998  0.0   0.0  0.0       0.0     0.0           0.0  0.0      0.0   \n",
       "3999  0.0   0.0  0.0       0.0     0.0           0.0  0.0      0.0   \n",
       "\n",
       "      abdominoperineal  abe  ...  zoster  zovirax  zucker  zurich  zygomycete  \\\n",
       "0                  0.0  0.0  ...     0.0      0.0     0.0     0.0         0.0   \n",
       "1                  0.0  0.0  ...     0.0      0.0     0.0     0.0         0.0   \n",
       "2                  0.0  0.0  ...     0.0      0.0     0.0     0.0         0.0   \n",
       "3                  0.0  0.0  ...     0.0      0.0     0.0     0.0         0.0   \n",
       "4                  0.0  0.0  ...     0.0      0.0     0.0     0.0         0.0   \n",
       "...                ...  ...  ...     ...      ...     ...     ...         ...   \n",
       "3995               0.0  0.0  ...     0.0      0.0     0.0     0.0         0.0   \n",
       "3996               0.0  0.0  ...     0.0      0.0     0.0     0.0         0.0   \n",
       "3997               0.0  0.0  ...     0.0      0.0     0.0     0.0         0.0   \n",
       "3998               0.0  0.0  ...     0.0      0.0     0.0     0.0         0.0   \n",
       "3999               0.0  0.0  ...     0.0      0.0     0.0     0.0         0.0   \n",
       "\n",
       "      zygomycetes  zygomycosis  zygotic  zymosan  zypab  \n",
       "0             0.0          0.0      0.0      0.0    0.0  \n",
       "1             0.0          0.0      0.0      0.0    0.0  \n",
       "2             0.0          0.0      0.0      0.0    0.0  \n",
       "3             0.0          0.0      0.0      0.0    0.0  \n",
       "4             0.0          0.0      0.0      0.0    0.0  \n",
       "...           ...          ...      ...      ...    ...  \n",
       "3995          0.0          0.0      0.0      0.0    0.0  \n",
       "3996          0.0          0.0      0.0      0.0    0.0  \n",
       "3997          0.0          0.0      0.0      0.0    0.0  \n",
       "3998          0.0          0.0      0.0      0.0    0.0  \n",
       "3999          0.0          0.0      0.0      0.0    0.0  \n",
       "\n",
       "[4000 rows x 11291 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BONA > SR > TF-IDF\n",
    "bona_sr_tfidf = tf_idf(bona_sr)\n",
    "bona_sr_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save csv\n",
    "bona_sr_tfidf.to_csv('pubmed/bona_sr_tfidf.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aab</th>\n",
       "      <th>aabc</th>\n",
       "      <th>aac</th>\n",
       "      <th>aagarose</th>\n",
       "      <th>abbott</th>\n",
       "      <th>abbreviation</th>\n",
       "      <th>abc</th>\n",
       "      <th>abdomen</th>\n",
       "      <th>abdominoperineal</th>\n",
       "      <th>abe</th>\n",
       "      <th>...</th>\n",
       "      <th>zoster</th>\n",
       "      <th>zovirax</th>\n",
       "      <th>zucker</th>\n",
       "      <th>zurich</th>\n",
       "      <th>zygomycete</th>\n",
       "      <th>zygomycetes</th>\n",
       "      <th>zygomycosis</th>\n",
       "      <th>zygotic</th>\n",
       "      <th>zymosan</th>\n",
       "      <th>zypab</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 11291 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      aab  aabc  aac  aagarose  abbott  abbreviation  abc  abdomen  \\\n",
       "0     0.0   0.0  0.0       0.0     0.0           0.0  0.0      0.0   \n",
       "1     0.0   0.0  0.0       0.0     0.0           0.0  0.0      0.0   \n",
       "2     0.0   0.0  0.0       0.0     0.0           0.0  0.0      0.0   \n",
       "3     0.0   0.0  0.0       0.0     0.0           0.0  0.0      0.0   \n",
       "4     0.0   0.0  0.0       0.0     0.0           0.0  0.0      0.0   \n",
       "...   ...   ...  ...       ...     ...           ...  ...      ...   \n",
       "3995  0.0   0.0  0.0       0.0     0.0           0.0  0.0      0.0   \n",
       "3996  0.0   0.0  0.0       0.0     0.0           0.0  0.0      0.0   \n",
       "3997  0.0   0.0  0.0       0.0     0.0           0.0  0.0      0.0   \n",
       "3998  0.0   0.0  0.0       0.0     0.0           0.0  0.0      0.0   \n",
       "3999  0.0   0.0  0.0       0.0     0.0           0.0  0.0      0.0   \n",
       "\n",
       "      abdominoperineal  abe  ...  zoster  zovirax  zucker  zurich  zygomycete  \\\n",
       "0                  0.0  0.0  ...     0.0      0.0     0.0     0.0         0.0   \n",
       "1                  0.0  0.0  ...     0.0      0.0     0.0     0.0         0.0   \n",
       "2                  0.0  0.0  ...     0.0      0.0     0.0     0.0         0.0   \n",
       "3                  0.0  0.0  ...     0.0      0.0     0.0     0.0         0.0   \n",
       "4                  0.0  0.0  ...     0.0      0.0     0.0     0.0         0.0   \n",
       "...                ...  ...  ...     ...      ...     ...     ...         ...   \n",
       "3995               0.0  0.0  ...     0.0      0.0     0.0     0.0         0.0   \n",
       "3996               0.0  0.0  ...     0.0      0.0     0.0     0.0         0.0   \n",
       "3997               0.0  0.0  ...     0.0      0.0     0.0     0.0         0.0   \n",
       "3998               0.0  0.0  ...     0.0      0.0     0.0     0.0         0.0   \n",
       "3999               0.0  0.0  ...     0.0      0.0     0.0     0.0         0.0   \n",
       "\n",
       "      zygomycetes  zygomycosis  zygotic  zymosan  zypab  \n",
       "0             0.0          0.0      0.0      0.0    0.0  \n",
       "1             0.0          0.0      0.0      0.0    0.0  \n",
       "2             0.0          0.0      0.0      0.0    0.0  \n",
       "3             0.0          0.0      0.0      0.0    0.0  \n",
       "4             0.0          0.0      0.0      0.0    0.0  \n",
       "...           ...          ...      ...      ...    ...  \n",
       "3995          0.0          0.0      0.0      0.0    0.0  \n",
       "3996          0.0          0.0      0.0      0.0    0.0  \n",
       "3997          0.0          0.0      0.0      0.0    0.0  \n",
       "3998          0.0          0.0      0.0      0.0    0.0  \n",
       "3999          0.0          0.0      0.0      0.0    0.0  \n",
       "\n",
       "[4000 rows x 11291 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read csv\n",
    "bona_sr_tfidf = pd.read_csv('pubmed/bona_sr_tfidf.csv')\n",
    "bona_sr_tfidf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn.cluster.k_means_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcluster\u001b[39;00m \u001b[39mimport\u001b[39;00m KMeans\n\u001b[1;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mspherecluster\u001b[39;00m \u001b[39mimport\u001b[39;00m SphericalKMeans\n\u001b[0;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m \u001b[39mimport\u001b[39;00m pyplot \u001b[39mas\u001b[39;00m plt\n\u001b[0;32m      4\u001b[0m get_ipython()\u001b[39m.\u001b[39mrun_line_magic(\u001b[39m'\u001b[39m\u001b[39mmatplotlib\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39minline\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\spherecluster\\__init__.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m__future__\u001b[39;00m \u001b[39mimport\u001b[39;00m absolute_import\n\u001b[1;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mspherical_kmeans\u001b[39;00m \u001b[39mimport\u001b[39;00m SphericalKMeans\n\u001b[0;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mvon_mises_fisher_mixture\u001b[39;00m \u001b[39mimport\u001b[39;00m VonMisesFisherMixture\n\u001b[0;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m \u001b[39mimport\u001b[39;00m sample_vMF\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\spherecluster\\spherical_kmeans.py:7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msparse\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39msp\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcluster\u001b[39;00m \u001b[39mimport\u001b[39;00m KMeans\n\u001b[1;32m----> 7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcluster\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mk_means_\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m      8\u001b[0m     _check_sample_weight,\n\u001b[0;32m      9\u001b[0m     _init_centroids,\n\u001b[0;32m     10\u001b[0m     _labels_inertia,\n\u001b[0;32m     11\u001b[0m     _tolerance,\n\u001b[0;32m     12\u001b[0m     _validate_center_shape,\n\u001b[0;32m     13\u001b[0m )\n\u001b[0;32m     14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m check_array, check_random_state\n\u001b[0;32m     15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mvalidation\u001b[39;00m \u001b[39mimport\u001b[39;00m _num_samples\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn.cluster.k_means_'"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from spherecluster import SphericalKMeans\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ZephZ\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([1, 1, 1, ..., 0, 1, 0]), array([[ 5.42101086e-20,  3.79470760e-19,  1.93123512e-19, ...,\n",
      "         1.96511644e-19,  2.43945489e-19, -8.40256684e-19],\n",
      "       [ 1.92048056e-04,  8.93899679e-05,  3.15107759e-05, ...,\n",
      "         6.37731321e-05,  4.90989071e-05,  1.57197896e-04]]))\n"
     ]
    }
   ],
   "source": [
    "# K-Means++\n",
    "def kmeansPlus(n, data):\n",
    "    kmp = KMeans(n_clusters = n)\n",
    "    predict = kmp.fit_predict(data)\n",
    "    centroid = kmp.cluster_centers_\n",
    "    return predict, centroid\n",
    "\n",
    "print(kmeansPlus(2, bona_sr_tfidf))\n",
    "\n",
    "# Spherical K-Means\n",
    "# skm = SphericalKMeans(n_clusters=n)\n",
    "# skm.fit(X)\n",
    "\n",
    "# skm.cluster_centers_\n",
    "# skm.labels_\n",
    "# skm.inertia_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics.cluster import contingency_matrix\n",
    "from sklearn.metrics import adjusted_mutual_info_score\n",
    "\n",
    "# Silhouette Score\n",
    "# silhouette_score(labels_true, labels_pred)\n",
    "\n",
    "# Purity\n",
    "# contingency_matrix(labels_true, labels_pred)\n",
    "\n",
    "# AMI\n",
    "# adjusted_mutual_info_score(labels_true, labels_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ab696253bf1cbd9262a120019f89a6af5e719602af9132e0a92b18d085125844"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
