{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "# import nltk\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.sparse import spdiags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "# from spherecluster import SphericalKMeans\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics.cluster import contingency_matrix\n",
    "from sklearn.metrics import adjusted_mutual_info_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pubmed\n",
    "pubmed = []\n",
    "docList = glob.glob(os.path.join(os.getcwd(), \"Datasets/pubmed/\", \"*.txt\"))\n",
    "\n",
    "for docPath in tqdm(docList):\n",
    "    # get doc file name\n",
    "    docName = os.path.basename(docPath).split('.')[0]\n",
    "    className = docName[:3]\n",
    "    \n",
    "    with open(docPath, encoding=\"utf8\") as doc:\n",
    "        # insert [class, docs, feature]\n",
    "        pubmed.append([className, docName, doc.read().replace('\\n', ' ')])\n",
    "\n",
    "# # make dataframe\n",
    "# dataframe = pd.DataFrame(data=pubmed, columns=['class', 'document', 'feature']) \n",
    "\n",
    "# # export pubmed raw\n",
    "# dataframe.to_csv('pubmed/raw.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scopus\n",
    "scopus = []\n",
    "docList = glob.glob(os.path.join(os.getcwd(), \"Datasets/scopus/\", \"*\"))\n",
    "\n",
    "for docPath in tqdm(docList):\n",
    "    # get doc file name\n",
    "    docName = os.path.basename(docPath)\n",
    "    className = docName.split('-')[0]\n",
    "    \n",
    "    with open(docPath, encoding=\"utf8\") as doc:\n",
    "        # insert [class, docs, feature]\n",
    "        scopus.append([className, docName, doc.read().replace('\\n', ' ')])\n",
    "\n",
    "# make dataframe\n",
    "dataframe = pd.DataFrame(data=scopus, columns=['class', 'document', 'feature']) \n",
    "\n",
    "# export pubmed raw\n",
    "dataframe.to_csv('scopus/raw.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataframe Raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv\n",
    "pubmedRaw = pd.read_csv('pubmed/raw.csv')\n",
    "scopusRaw = pd.read_csv('scopus/raw.csv')\n",
    "\n",
    "# get feature\n",
    "pubmedFeatures = pubmedRaw.loc[:, 'feature']\n",
    "scopusFeatures = scopusRaw.loc[:, 'feature']\n",
    "scopusFeatures"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocesing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# cleaning\n",
    "def cleaning(features):\n",
    "    result = []\n",
    "    for feature in features:\n",
    "        regex = re.sub(r'[^a-zA-Z\\s]', '', feature)\n",
    "        result.append(regex)\n",
    "    return result\n",
    "\n",
    "# case folding\n",
    "def caseFolding(features):\n",
    "    result = []\n",
    "    for feature in features:\n",
    "        lower = feature.lower()\n",
    "        result.append(lower)\n",
    "    return result\n",
    "\n",
    "# tokenization\n",
    "def tokenization(features):\n",
    "    result = []\n",
    "    for feature in features:\n",
    "        token = word_tokenize(feature)\n",
    "        result.append(token)\n",
    "    return result\n",
    "\n",
    "# stopwords removal\n",
    "def stopWords(features):\n",
    "    result = []\n",
    "    stopWords = set(stopwords.words('english'))\n",
    "    for token in features:\n",
    "        cleanedFeature = [feature for feature in token if feature not in stopWords]\n",
    "        result.append(cleanedFeature)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "def preprocessing(features):\n",
    "    clean = cleaning(features)\n",
    "    case = caseFolding(clean)\n",
    "    token = tokenization(case)\n",
    "    preprocessed = stopWords(token)\n",
    "    return preprocessed\n",
    "    \n",
    "pubmedPreprocessed = preprocessing(pubmedFeatures)\n",
    "scopusPreprocessed = preprocessing(scopusFeatures)\n",
    "# print(scopusPreprocessed[0])\n",
    "\n",
    "# export pubmed clean\n",
    "for i in range(len(pubmedPreprocessed)):\n",
    "    pubmedRaw.loc[i, 'feature'] = ' '.join(pubmedPreprocessed[i])\n",
    "pubmedRaw.to_csv('pubmed/clean.csv', index=False)\n",
    "\n",
    "# export scopus clean\n",
    "for i in range(len(scopusPreprocessed)):\n",
    "    scopusRaw.loc[i, 'feature'] = ' '.join(scopusPreprocessed[i])\n",
    "scopusRaw.to_csv('scopus/clean.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Daraframe Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv\n",
    "pubmedClean = pd.read_csv('pubmed/clean.csv')\n",
    "scopusClean = pd.read_csv('scopus/clean.csv')\n",
    "\n",
    "# get feature\n",
    "pubmedFeatures = pubmedClean.loc[:, 'feature']\n",
    "scopusFeatures = scopusClean.loc[:, 'feature']\n",
    "scopusClean"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Forming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "def featureForming(features, dataframe):\n",
    "    # BOAW\n",
    "    dataframe.rename(columns={'feature': 'BOAW'}, inplace=True)\n",
    "    for i in tqdm(range(len(features))):\n",
    "        # BON\n",
    "        dataframe.loc[i, 'BON'] = ' '.join(TextBlob(features[i]).noun_phrases)\n",
    "        # BONA\n",
    "        dataframe.loc[i, 'BONA'] = ' '.join([word for (word, tag) in TextBlob(features[i]).tags if tag[:2]=='NN' or tag[:2]=='JJ'])\n",
    "\n",
    "featureForming(pubmedFeatures, pubmedClean)\n",
    "featureForming(scopusFeatures, scopusClean)\n",
    "# print(scopusClean)\n",
    "\n",
    "pubmedClean.to_csv('pubmed/formed.csv', index=False)\n",
    "scopusClean.to_csv('scopus/formed.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataframe Formed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             CONCRETE\n",
       "1             CONCRETE\n",
       "2             CONCRETE\n",
       "3             CONCRETE\n",
       "4             CONCRETE\n",
       "             ...      \n",
       "2795    TECTONICPLATES\n",
       "2796    TECTONICPLATES\n",
       "2797    TECTONICPLATES\n",
       "2798    TECTONICPLATES\n",
       "2799    TECTONICPLATES\n",
       "Name: class, Length: 2800, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read csv\n",
    "pubmedFormed = pd.read_csv('pubmed/formed.csv')\n",
    "scopusFormed = pd.read_csv('scopus/formed.csv')\n",
    "\n",
    "# get feature\n",
    "# pubmed\n",
    "pubmedClass = pubmedFormed.loc[:, 'class']\n",
    "pubmed_boaw = pubmedFormed.loc[:, 'BOAW']\n",
    "pubmed_bon = pubmedFormed.loc[:, 'BON']\n",
    "pubmed_bona = pubmedFormed.loc[:, 'BONA']\n",
    "\n",
    "# scopus\n",
    "scopusClass = scopusFormed.loc[:, 'class']\n",
    "scopus_boaw = scopusFormed.loc[:, 'BOAW']\n",
    "scopus_bon = scopusFormed.loc[:, 'BON']\n",
    "scopus_bona = scopusFormed.loc[:, 'BONA']\n",
    "scopusClass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SFS\n",
    "def symbolic(features, classes):\n",
    "    # get tf weights\n",
    "    tfVec = CountVectorizer()\n",
    "    tf = tfVec.fit_transform(features)\n",
    "\n",
    "    # define weights into dataframe\n",
    "    featureName = tfVec.get_feature_names_out()\n",
    "    featureWeight = tf.todense()\n",
    "    df = pd.DataFrame(featureWeight, columns=featureName)\n",
    "    df.loc[:, 'class'] = classes\n",
    "    # return df\n",
    "\n",
    "    # count mean & standard deviation\n",
    "    mean = df.groupby('class').mean().reset_index()\n",
    "    std = df.groupby('class').std().reset_index()\n",
    "\n",
    "    totalSm = []\n",
    "    for col in tqdm(mean.columns):\n",
    "        if col != 'class':\n",
    "            # count interval per features\n",
    "            interval = []\n",
    "            for row in range(len(mean)):\n",
    "                meanA = mean.loc[row, col]\n",
    "                stdA = std.loc[row, col]\n",
    "                interval.append([meanA - stdA, meanA + stdA])\n",
    "            \n",
    "            # count similarity per feature\n",
    "            similarity = 0\n",
    "            for itvA in interval:\n",
    "                # count similarity per class\n",
    "                smClass = []\n",
    "                for itvB in interval:\n",
    "                    if itvA != itvB:\n",
    "                        smClass.append((min(itvA[1], itvB[1]) - max(itvA[0], itvB[0])) / (itvB[1] - itvB[0]))\n",
    "\n",
    "                # count total similarity\n",
    "                similarity += np.nansum(smClass)\n",
    "            totalSm.append(similarity)\n",
    "\n",
    "    # count average total similarity\n",
    "    avgTotalSm = np.mean(totalSm)\n",
    "\n",
    "    # select feature that totalSm > avgTotalSm\n",
    "    selected = []\n",
    "    for i in range(len(totalSm)):\n",
    "        if totalSm[i] > avgTotalSm:\n",
    "            selected.append(df.columns[i])\n",
    "    # return len(selected)\n",
    "    return selected\n",
    "\n",
    "# sfx = symbolic(pubmedBona, pubmedClass)\n",
    "# print(sfx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-RF\n",
    "def tf_rf(features, classes):\n",
    "    # get tf weights\n",
    "    tfVec = CountVectorizer()\n",
    "    tf = tfVec.fit_transform(features)\n",
    "\n",
    "    # get classes weights\n",
    "    clsVec = LabelBinarizer()\n",
    "    cls = clsVec.fit_transform(classes)\n",
    "    # return cls, cls.shape\n",
    "\n",
    "    # if has only 1 class, add negative class\n",
    "    if cls.shape[1] == 1:\n",
    "        cls = np.append(1 - cls, cls, axis=1)\n",
    "\n",
    "    # count class contain feature (1 if contain, 0 if not, then convert to float)\n",
    "    featureDoc = ((cls.T * tf) > 0).astype(np.float64)\n",
    "    # return featureDoc.shape\n",
    "\n",
    "    for classC in range(cls.shape[1]):\n",
    "        # featureDoc.sum(axis=0) - featureDoc[classC] is the sum of all rows except classC\n",
    "        featureDoc[classC] /= np.maximum(1., featureDoc.sum(axis=0) - featureDoc[classC])\n",
    "\n",
    "    # count rf\n",
    "    rf = np.mean(np.log2(2 + featureDoc, out=featureDoc), axis=0)\n",
    "\n",
    "    # count tf-rf & transform to sparse matrix\n",
    "    totalFeature = rf.shape[0]\n",
    "    tfRf = tf * spdiags(rf, 0, totalFeature, totalFeature)\n",
    "\n",
    "    # define weights into dataframe\n",
    "    featureName = tfVec.get_feature_names_out()\n",
    "    featureWeight = tfRf.todense()\n",
    "    df = pd.DataFrame(featureWeight, columns=featureName)\n",
    "    df.loc[:, 'class'] = classes\n",
    "    # return df\n",
    "\n",
    "    # count weight by class\n",
    "    mean = df.groupby('class').mean()\n",
    "    result = (mean/mean.max()).sum()\n",
    "    # return result\n",
    "\n",
    "    # select minimum weighted features\n",
    "    selected = []\n",
    "    for i in tqdm(range(len(result))):\n",
    "        if result[i] > np.mean(result):\n",
    "            selected.append(df.columns[i])\n",
    "    # return len(selected)\n",
    "    return selected\n",
    "\n",
    "# rfx = tf_rf(pubmedBona, pubmedClass)\n",
    "# print(rfx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Symbolic Relevance\n",
    "def symbolic_relevance(features, classes):\n",
    "    # get sfs\n",
    "    sfs = symbolic(features, classes)\n",
    "    # get tf-rf\n",
    "    tfrf = tf_rf(features, classes)\n",
    "\n",
    "    # intersect features\n",
    "    selected = list(np.intersect1d(sfs, tfrf))\n",
    "    print('sfs:', len(sfs), 'tfrf:', len(tfrf), 'selected:', len(selected))\n",
    "\n",
    "    # update features\n",
    "    token = tokenization(features)\n",
    "    result = []\n",
    "    for row in tqdm(token):\n",
    "        words = [word for word in row if word in selected]\n",
    "        result.append(words)\n",
    "    return result\n",
    "\n",
    "# srx = symbolic_relevance(scopusBona, scopusClass)\n",
    "# print(srx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pubmed\n",
    "pubmed_boaw_sr = symbolic_relevance(pubmed_boaw, pubmedClass)\n",
    "pubmed_bon_sr = symbolic_relevance(pubmed_bon, pubmedClass)\n",
    "pubmed_bona_sr = symbolic_relevance(pubmed_bona, pubmedClass)\n",
    "\n",
    "# scopus\n",
    "scopus_boaw_sr = symbolic_relevance(scopus_boaw, scopusClass)\n",
    "scopus_bon_sr = symbolic_relevance(scopus_bon, scopusClass)\n",
    "scopus_bona_sr = symbolic_relevance(scopus_bona, scopusClass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4000/4000 [00:00<00:00, 4562.78it/s]\n",
      "100%|██████████| 2800/2800 [00:00<00:00, 5388.66it/s]\n"
     ]
    }
   ],
   "source": [
    "# save csv\n",
    "# pubmed\n",
    "for i in tqdm(range(len(pubmedFormed))):\n",
    "    # BOAW\n",
    "    pubmedFormed.loc[i, 'BOAW_SR'] = ' '.join(pubmed_boaw_sr[i])\n",
    "    # BON\n",
    "    pubmedFormed.loc[i, 'BON_SR'] = ' '.join(pubmed_bon_sr[i])\n",
    "    # BONA\n",
    "    pubmedFormed.loc[i, 'BONA_SR'] = ' '.join(pubmed_bona_sr[i])\n",
    "\n",
    "pubmedFormed.to_csv('pubmed/selected.csv', index=False)\n",
    "\n",
    "# scopus\n",
    "for i in tqdm(range(len(scopusFormed))):\n",
    "    # BOAW\n",
    "    scopusFormed.loc[i, 'BOAW_SR'] = ' '.join(scopus_boaw_sr[i])\n",
    "    # BON\n",
    "    scopusFormed.loc[i, 'BON_SR'] = ' '.join(scopus_bon_sr[i])\n",
    "    # BONA\n",
    "    scopusFormed.loc[i, 'BONA_SR'] = ' '.join(scopus_bona_sr[i])\n",
    "\n",
    "scopusFormed.to_csv('scopus/selected.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       amounts temporal type tissue patients diagnosi...\n",
       "1       criteria type diagnosis patients memory charac...\n",
       "2       synthesis cglucose tissue synthesis co cglucos...\n",
       "3       pattern type observations patients type dat co...\n",
       "4       blood rate bodies amino acids blood rate bodie...\n",
       "                              ...                        \n",
       "3995    major complex genes outcome null alleles assoc...\n",
       "3996    cohort patients course patients clinical exami...\n",
       "3997    main purpose paper trace describe principal cl...\n",
       "3998    virus inhibit cell antigen pathway recombinant...\n",
       "3999    progression usefulness lymphocyte purpose usef...\n",
       "Name: BON_SR, Length: 4000, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read csv\n",
    "pubmedSelected = pd.read_csv('pubmed/selected.csv')\n",
    "scopusSelected = pd.read_csv('scopus/selected.csv')\n",
    "\n",
    "# get feature\n",
    "# pubmed\n",
    "pubmedClass = pubmedSelected.loc[:, 'class']\n",
    "pubmed_boaw = pubmedSelected.loc[:, 'BOAW']\n",
    "pubmed_bon = pubmedSelected.loc[:, 'BON']\n",
    "pubmed_bona = pubmedSelected.loc[:, 'BONA']\n",
    "pubmed_boaw_sr = pubmedSelected.loc[:, 'BOAW_SR']\n",
    "pubmed_bon_sr = pubmedSelected.loc[:, 'BON_SR']\n",
    "pubmed_bona_sr = pubmedSelected.loc[:, 'BONA_SR']\n",
    "\n",
    "# scopus\n",
    "scopusClass = scopusSelected.loc[:, 'class']\n",
    "scopus_boaw = scopusSelected.loc[:, 'BOAW']\n",
    "scopus_bon = scopusSelected.loc[:, 'BON']\n",
    "scopus_bona = scopusSelected.loc[:, 'BONA']\n",
    "scopus_boaw_sr = scopusSelected.loc[:, 'BOAW_SR']\n",
    "scopus_bon_sr = scopusSelected.loc[:, 'BON_SR']\n",
    "scopus_bona_sr = scopusSelected.loc[:, 'BONA_SR']\n",
    "pubmed_bon_sr"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Term Weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF\n",
    "def tf(features):\n",
    "    # get tf weights & transform to sparse matrix\n",
    "    tfVec = CountVectorizer()\n",
    "    tf = tfVec.fit_transform(features.fillna(' '))\n",
    "    return tf\n",
    "\n",
    "# tfx = tf(bona)\n",
    "# print(tfx)\n",
    "\n",
    "# TF-IDF\n",
    "def tf_idf(features):\n",
    "    # get tf-idf weights & transform to sparse matrix\n",
    "    tfIdfVec = TfidfVectorizer()\n",
    "    tfIdf = tfIdfVec.fit_transform(features.fillna(' '))\n",
    "    return tfIdf\n",
    "\n",
    "# idfx = tf_idf(scopusBonSr)\n",
    "# print(idfx)\n",
    "\n",
    "# TF-IDF-ICF\n",
    "def tf_idf_icf(features, classes):\n",
    "    # count tf-idf\n",
    "    tfIdf = tf_idf(features)\n",
    "\n",
    "    # get classes weights\n",
    "    clsVec = LabelBinarizer()\n",
    "    cls = clsVec.fit_transform(classes)\n",
    "\n",
    "    # count total class\n",
    "    totalClass = cls.shape[1]\n",
    "\n",
    "    # count class contain feature (1 if contain, then convert to float, and sum per class)\n",
    "    classFeature = ((cls.T * tfIdf) > 0).astype(np.float64).sum(axis=0)\n",
    "\n",
    "    # count icf\n",
    "    icf = []\n",
    "    for featureId in range(tfIdf.shape[1]):\n",
    "        icf.append(1 + math.log(totalClass / classFeature[featureId]))\n",
    "    icf = np.array(icf)\n",
    "\n",
    "    # get tf-idf-icf weights & transform to sparse matrix\n",
    "    totalFeature = icf.shape[0]\n",
    "    tfIdfIcf = tfIdf * spdiags(icf, 0, totalFeature, totalFeature)\n",
    "    return tfIdfIcf\n",
    "\n",
    "# icfx = tf_idf_icf(pubmedBonSr, pubmedClass)\n",
    "# print(icfx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# term weighting\n",
    "\n",
    "# pubmed\n",
    "# BOAW > SR > TF\n",
    "pubmed_boaw_sr_tf = tf(pubmed_boaw_sr)\n",
    "# BOAW > SR > TF-IDF\n",
    "pubmed_boaw_sr_tfIdf = tf_idf(pubmed_boaw_sr)\n",
    "# BOAW > SR > TF-IDF-ICF\n",
    "pubmed_boaw_sr_tfIdfIcf = tf_idf_icf(pubmed_boaw_sr, pubmedClass)\n",
    "# BOAW > TF-IDF\n",
    "pubmed_boaw_tfIdf = tf_idf(pubmed_boaw)\n",
    "# BOAW > TF-IDF-ICF\n",
    "pubmed_boaw_tfIdfIcf = tf_idf_icf(pubmed_boaw, pubmedClass)\n",
    "\n",
    "# BON > SR > TF\n",
    "pubmed_bon_sr_tf = tf(pubmed_bon_sr)\n",
    "# BON > SR > TF-IDF\n",
    "pubmed_bon_sr_tfIdf = tf_idf(pubmed_bon_sr)\n",
    "# BON > SR > TF-IDF-ICF\n",
    "pubmed_bon_sr_tfIdfIcf = tf_idf_icf(pubmed_bon_sr, pubmedClass)\n",
    "# BON > TF-IDF\n",
    "pubmed_bon_tfIdf = tf_idf(pubmed_bon)\n",
    "# BON > TF-IDF-ICF\n",
    "pubmed_bon_tfIdfIcf = tf_idf_icf(pubmed_bon, pubmedClass)\n",
    "\n",
    "# BONA > SR > TF\n",
    "pubmed_bona_sr_tf = tf(pubmed_bona_sr)\n",
    "# BONA > SR > TF-IDF\n",
    "pubmed_bona_sr_tfIdf = tf_idf(pubmed_bona_sr)\n",
    "# BONA > SR > TF-IDF-ICF\n",
    "pubmed_bona_sr_tfIdfIcf = tf_idf_icf(pubmed_bona_sr, pubmedClass)\n",
    "# BONA > TF-IDF\n",
    "pubmed_bona_tfIdf = tf_idf(pubmed_bona)\n",
    "# BONA > TF-IDF-ICF\n",
    "pubmed_bona_tfIdfIcf = tf_idf_icf(pubmed_bona, pubmedClass)\n",
    "\n",
    "\n",
    "# scopus\n",
    "# BOAW > SR > TF\n",
    "scopus_boaw_sr_tf = tf(scopus_boaw_sr)\n",
    "# BOAW > SR > TF-IDF\n",
    "scopus_boaw_sr_tfIdf = tf_idf(scopus_boaw_sr)\n",
    "# BOAW > SR > TF-IDF-ICF\n",
    "scopus_boaw_sr_tfIdfIcf = tf_idf_icf(scopus_boaw_sr, scopusClass)\n",
    "# BOAW > TF-IDF\n",
    "scopus_boaw_tfIdf = tf_idf(scopus_boaw)\n",
    "# BOAW > TF-IDF-ICF\n",
    "scopus_boaw_tfIdfIcf = tf_idf_icf(scopus_boaw, scopusClass)\n",
    "\n",
    "# BON > SR > TF\n",
    "scopus_bon_sr_tf = tf(scopus_bon_sr)\n",
    "# BON > SR > TF-IDF\n",
    "scopus_bon_sr_tfIdf = tf_idf(scopus_bon_sr)\n",
    "# BON > SR > TF-IDF-ICF\n",
    "scopus_bon_sr_tfIdfIcf = tf_idf_icf(scopus_bon_sr, scopusClass)\n",
    "# BON > TF-IDF\n",
    "scopus_bon_tfIdf = tf_idf(scopus_bon)\n",
    "# BON > TF-IDF-ICF\n",
    "scopus_bon_tfIdfIcf = tf_idf_icf(scopus_bon, scopusClass)\n",
    "\n",
    "# BONA > SR > TF\n",
    "scopus_bona_sr_tf = tf(scopus_bona_sr)\n",
    "# BONA > SR > TF-IDF\n",
    "scopus_bona_sr_tfIdf = tf_idf(scopus_bona_sr)\n",
    "# BONA > SR > TF-IDF-ICF\n",
    "scopus_bona_sr_tfIdfIcf = tf_idf_icf(scopus_bona_sr, scopusClass)\n",
    "# BONA > TF-IDF\n",
    "scopus_bona_tfIdf = tf_idf(scopus_bona)\n",
    "# BONA > TF-IDF-ICF\n",
    "scopus_bona_tfIdfIcf = tf_idf_icf(scopus_bona, scopusClass)\n",
    "# pubmed_bona_sr_tfIdfIcf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Means++\n",
    "def kmeans_plus(data):\n",
    "    cluster = {\n",
    "        'label': []\n",
    "    }\n",
    "    \n",
    "    for k in tqdm(range(2, 11)):\n",
    "        kmp = KMeans(n_clusters=k, init = 'k-means++')\n",
    "        kmp.fit(data)\n",
    "        cluster['label'].append(kmp.labels_)\n",
    "    return cluster\n",
    "\n",
    "# kmpx = kmeansPlus(pubmed_bona_sr_tfIdfIcf)\n",
    "# print(kmpx)\n",
    "\n",
    "# # Spherical K-Means\n",
    "# def spher_kmeans(data):\n",
    "#     label = []\n",
    "#     for k in tqdm(range(2, 11)):\n",
    "#         skm = SphericalKMeans(n_clusters=k)\n",
    "#         skm.fit(data)\n",
    "#         label = skm.labels_\n",
    "\n",
    "# skmx = spherKmeans(3, bona_sr_tfidf)\n",
    "# print(skmx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': [array([0, 0, 0, ..., 0, 1, 0]), array([1, 1, 1, ..., 1, 0, 1]), array([2, 1, 1, ..., 1, 3, 1]), array([0, 4, 4, ..., 4, 2, 4]), array([4, 1, 1, ..., 1, 2, 1]), array([2, 3, 6, ..., 3, 0, 6]), array([2, 6, 6, ..., 6, 1, 5]), array([3, 1, 7, ..., 1, 0, 7]), array([1, 9, 3, ..., 3, 2, 3])]}\n"
     ]
    }
   ],
   "source": [
    "# get K-Means++ clusters\n",
    "# pubmed\n",
    "# BOAW > SR > TF > K-Means++\n",
    "pubmed_boaw_sr_tf_kmeansPlus = kmeans_plus(pubmed_boaw_sr_tf)\n",
    "# BOAW > SR > TF-IDF > K-Means++\n",
    "pubmed_boaw_sr_tfIdf_kmeansPlus = kmeans_plus(pubmed_boaw_sr_tfIdf)\n",
    "# BOAW > SR > TF-IDF-ICF > K-Means++\n",
    "pubmed_boaw_sr_tfIdfIcf_kmeansPlus = kmeans_plus(pubmed_boaw_sr_tfIdfIcf)\n",
    "# BOAW > TF-IDF > K-Means++\n",
    "pubmed_boaw_tfIdf_kmeansPlus = kmeans_plus(pubmed_boaw_tfIdf)\n",
    "# BOAW > TF-IDF-ICF > K-Means++\n",
    "pubmed_boaw_tfIdfIcf_kmeansPlus = kmeans_plus(pubmed_boaw_tfIdfIcf)\n",
    "\n",
    "# BON > SR > TF > K-Means++\n",
    "pubmed_bon_sr_tf_kmeansPlus = kmeans_plus(pubmed_bon_sr_tf)\n",
    "# BON > SR > TF-IDF > K-Means++\n",
    "pubmed_bon_sr_tfIdf_kmeansPlus = kmeans_plus(pubmed_bon_sr_tfIdf)\n",
    "# BON > SR > TF-IDF-ICF > K-Means++\n",
    "pubmed_bon_sr_tfIdfIcf_kmeansPlus = kmeans_plus(pubmed_bon_sr_tfIdfIcf)\n",
    "# BON > TF-IDF > K-Means++\n",
    "pubmed_bon_tfIdf_kmeansPlus = kmeans_plus(pubmed_bon_tfIdf)\n",
    "# BON > TF-IDF-ICF > K-Means++\n",
    "pubmed_bon_tfIdfIcf_kmeansPlus = kmeans_plus(pubmed_bon_tfIdfIcf)\n",
    "\n",
    "# BONA > SR > TF > K-Means++\n",
    "pubmed_bona_sr_tf_kmeansPlus = kmeans_plus(pubmed_bona_sr_tf)\n",
    "# BONA > SR > TF-IDF > K-Means++\n",
    "pubmed_bona_sr_tfIdf_kmeansPlus = kmeans_plus(pubmed_bona_sr_tfIdf)\n",
    "# BONA > SR > TF-IDF-ICF > K-Means++\n",
    "pubmed_bona_sr_tfIdfIcf_kmeansPlus = kmeans_plus(pubmed_bona_sr_tfIdfIcf)\n",
    "# BONA > TF-IDF > K-Means++\n",
    "pubmed_bona_tfIdf_kmeansPlus = kmeans_plus(pubmed_bona_tfIdf)\n",
    "# BONA > TF-IDF-ICF > K-Means++\n",
    "pubmed_bona_tfIdfIcf_kmeansPlus = kmeans_plus(pubmed_bona_tfIdfIcf)\n",
    "\n",
    "\n",
    "# scopus\n",
    "# BOAW > SR > TF > K-Means++\n",
    "scopus_boaw_sr_tf_kmeansPlus = kmeans_plus(scopus_boaw_sr_tf)\n",
    "# BOAW > SR > TF-IDF > K-Means++\n",
    "scopus_boaw_sr_tfIdf_kmeansPlus = kmeans_plus(scopus_boaw_sr_tfIdf)\n",
    "# BOAW > SR > TF-IDF-ICF > K-Means++\n",
    "scopus_boaw_sr_tfIdfIcf_kmeansPlus = kmeans_plus(scopus_boaw_sr_tfIdfIcf)\n",
    "# BOAW > TF-IDF > K-Means++\n",
    "scopus_boaw_tfIdf_kmeansPlus = kmeans_plus(scopus_boaw_tfIdf)\n",
    "# BOAW > TF-IDF-ICF > K-Means++\n",
    "scopus_boaw_tfIdfIcf_kmeansPlus = kmeans_plus(scopus_boaw_tfIdfIcf)\n",
    "\n",
    "# BON > SR > TF > K-Means++\n",
    "scopus_bon_sr_tf_kmeansPlus = kmeans_plus(scopus_bon_sr_tf)\n",
    "# BON > SR > TF-IDF > K-Means++\n",
    "scopus_bon_sr_tfIdf_kmeansPlus = kmeans_plus(scopus_bon_sr_tfIdf)\n",
    "# BON > SR > TF-IDF-ICF > K-Means++\n",
    "scopus_bon_sr_tfIdfIcf_kmeansPlus = kmeans_plus(scopus_bon_sr_tfIdfIcf)\n",
    "# BON > TF-IDF > K-Means++\n",
    "scopus_bon_tfIdf_kmeansPlus = kmeans_plus(scopus_bon_tfIdf)\n",
    "# BON > TF-IDF-ICF > K-Means++\n",
    "scopus_bon_tfIdfIcf_kmeansPlus = kmeans_plus(scopus_bon_tfIdfIcf)\n",
    "\n",
    "# BONA > SR > TF > K-Means++\n",
    "scopus_bona_sr_tf_kmeansPlus = kmeans_plus(scopus_bona_sr_tf)\n",
    "# BONA > SR > TF-IDF > K-Means++\n",
    "scopus_bona_sr_tfIdf_kmeansPlus = kmeans_plus(scopus_bona_sr_tfIdf)\n",
    "# BONA > SR > TF-IDF-ICF > K-Means++\n",
    "scopus_bona_sr_tfIdfIcf_kmeansPlus = kmeans_plus(scopus_bona_sr_tfIdfIcf)\n",
    "# BONA > TF-IDF > K-Means++\n",
    "scopus_bona_tfIdf_kmeansPlus = kmeans_plus(scopus_bona_tfIdf)\n",
    "# BONA > TF-IDF-ICF > K-Means++\n",
    "scopus_bona_tfIdfIcf_kmeansPlus = kmeans_plus(scopus_bona_tfIdfIcf)\n",
    "# pubmed_bona_sr_tfIdfIcf_kmeansPlus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get Spherical K-Means clusters\n",
    "# Pubmed\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Silhouette Score\n",
    "def silhouette(document, label):\n",
    "    # count score\n",
    "    score = []\n",
    "    for k in tqdm(range(len(label))):\n",
    "        silhouetteScore = silhouette_score(document, label[k])\n",
    "        score.append(silhouetteScore)\n",
    "    return score\n",
    "\n",
    "# sx = silhouette(pubmed_bona_sr_tfIdfIcf, kmpx)\n",
    "# print(sx)\n",
    "\n",
    "# Purity\n",
    "def purity(classes, label):\n",
    "    # encode class\n",
    "    clsVec = LabelEncoder()\n",
    "    cls = clsVec.fit_transform(classes)\n",
    "    # add 1 to all list (to compare with label)\n",
    "    cls = cls + 1\n",
    "    \n",
    "    # count score\n",
    "    score = []\n",
    "    for k in tqdm(range(len(label))):\n",
    "        contingencyMatrix = contingency_matrix(cls, label[k])\n",
    "        purityScore = np.sum(np.amax(contingencyMatrix, axis=0)) / np.sum(contingencyMatrix)\n",
    "        score.append(purityScore)\n",
    "    return score\n",
    "\n",
    "# px = purity(pubmedClass, kmpx)\n",
    "# print(px)\n",
    "\n",
    "# AMI\n",
    "def ami(classes, label):\n",
    "    # encode class\n",
    "    clsVec = LabelEncoder()\n",
    "    cls = clsVec.fit_transform(classes)\n",
    "    # add 1 to all list (to compare with label)\n",
    "    cls = cls + 1\n",
    "    \n",
    "    # count score\n",
    "    score = []\n",
    "    for k in tqdm(range(len(label))):\n",
    "        amiScore = adjusted_mutual_info_score(classes, label[k])\n",
    "        score.append(amiScore)\n",
    "    return score\n",
    "\n",
    "# ax = ami(pubmedClass, kmpx)\n",
    "# print(ax)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ab696253bf1cbd9262a120019f89a6af5e719602af9132e0a92b18d085125844"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
