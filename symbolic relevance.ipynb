{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "# import nltk\n",
    "# nltk.download()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "pubmed = []\n",
    "\n",
    "# import pubmed\n",
    "docList = glob.glob(os.path.join(os.getcwd(), \"Datasets/pubmed/\", \"*.txt\"))\n",
    "\n",
    "for docPath in docList:\n",
    "    # get doc file name\n",
    "    docName = os.path.basename(docPath).split('.')[0]\n",
    "    \n",
    "    with open(docPath) as doc:\n",
    "        # insert [class, docs, feature]\n",
    "        pubmed.append([docName[:3], docName, doc.read().replace('\\n', ' ')])\n",
    "\n",
    "# print(pubmed)\n",
    "\n",
    "# make dataframe\n",
    "dataframe = pd.DataFrame(data=pubmed, columns=['class', 'document', 'feature']) \n",
    "\n",
    "# export pubmed raw\n",
    "dataframe.to_csv('pubmed/raw.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataframe raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv\n",
    "dataRaw = pd.read_csv('pubmed/raw.csv')\n",
    "# get feature\n",
    "features = dataRaw.loc[:, 'feature']\n",
    "dataRaw"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocesing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# cleaning\n",
    "def cleaning(features):\n",
    "    result = []\n",
    "    for feature in features:\n",
    "        regex = re.sub(r'[^a-zA-Z\\s]', '', feature)\n",
    "        result.append(regex)\n",
    "    return result\n",
    "\n",
    "# case folding\n",
    "def caseFolding(features):\n",
    "    result = []\n",
    "    for feature in features:\n",
    "        lower = feature.lower()\n",
    "        result.append(lower)\n",
    "    return result\n",
    "\n",
    "# tokenization\n",
    "def tokenization(features):\n",
    "    result = []\n",
    "    for feature in features:\n",
    "        token = word_tokenize(feature)\n",
    "        result.append(token)\n",
    "    return result\n",
    "\n",
    "# stopwords removal\n",
    "def stopWords(features):\n",
    "    result = []\n",
    "    stopWords = set(stopwords.words('english'))\n",
    "    for token in features:\n",
    "        cleanedFeature = [feature for feature in token if feature not in stopWords]\n",
    "        result.append(cleanedFeature)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning\n",
    "clean = cleaning(features)\n",
    "# print(clean)\n",
    "\n",
    "case = caseFolding(clean)\n",
    "# print(casefolding)\n",
    "\n",
    "token = tokenization(case)\n",
    "# print(tokenization)\n",
    "\n",
    "preprocessed = stopWords(token)\n",
    "# print(preprocessedFeature)\n",
    "\n",
    "# export pubmed clean\n",
    "for i in range(len(preprocessed)):\n",
    "    dataRaw.loc[i, 'feature'] = ' '.join(preprocessed[i])\n",
    "dataRaw.to_csv('pubmed/clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv\n",
    "dataClean = pd.read_csv('pubmed/clean.csv')\n",
    "# get feature\n",
    "features = dataClean.loc[:, 'feature']\n",
    "dataClean"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Forming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "# BOAW\n",
    "dataClean.rename(columns={'feature': 'BOAW'}, inplace=True)\n",
    "\n",
    "for i in tqdm(range(len(features))):\n",
    "    # BON\n",
    "    dataClean.loc[i,'BON'] = ' '.join(TextBlob(features[i]).noun_phrases)\n",
    "    # BONA\n",
    "    dataClean.loc[i,'BONA'] = ' '.join([word for (word, tag) in TextBlob(features[i]).tags if tag[:2]=='NN' or tag[:2]=='JJ'])\n",
    "\n",
    "# print(dataClean)\n",
    "\n",
    "dataClean.to_csv('pubmed/formed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>document</th>\n",
       "      <th>BOAW</th>\n",
       "      <th>BON</th>\n",
       "      <th>BONA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALZ</td>\n",
       "      <td>ALZ1</td>\n",
       "      <td>reduced amounts immunoreactive somatostatin te...</td>\n",
       "      <td>amounts immunoreactive somatostatin temporal c...</td>\n",
       "      <td>reduced amounts immunoreactive somatostatin te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALZ</td>\n",
       "      <td>ALZ10</td>\n",
       "      <td>diagnostic criteria primary neuronal degenerat...</td>\n",
       "      <td>diagnostic criteria primary neuronal degenerat...</td>\n",
       "      <td>diagnostic criteria primary neuronal degenerat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALZ</td>\n",
       "      <td>ALZ100</td>\n",
       "      <td>cacetylcholine synthesis ccarbon dioxide produ...</td>\n",
       "      <td>cacetylcholine synthesis ccarbon dioxide produ...</td>\n",
       "      <td>cacetylcholine synthesis ccarbon dioxide produ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ALZ</td>\n",
       "      <td>ALZ1000</td>\n",
       "      <td>pattern reading deterioration dementia alzheim...</td>\n",
       "      <td>pattern reading deterioration dementia alzheim...</td>\n",
       "      <td>pattern deterioration dementia alzheimer type ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ALZ</td>\n",
       "      <td>ALZ101</td>\n",
       "      <td>cerebral blood flow metabolic rate oxygen gluc...</td>\n",
       "      <td>cerebral blood flow metabolic rate oxygen gluc...</td>\n",
       "      <td>cerebral blood flow metabolic rate oxygen gluc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>HIV</td>\n",
       "      <td>HIV3996</td>\n",
       "      <td>major histocompatibility complex genes influen...</td>\n",
       "      <td>major histocompatibility complex genes outcome...</td>\n",
       "      <td>major histocompatibility complex genes influen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>HIV</td>\n",
       "      <td>HIV3997</td>\n",
       "      <td>hiv infection cohort haemophilic patients cour...</td>\n",
       "      <td>hiv infection cohort haemophilic patients cour...</td>\n",
       "      <td>hiv infection cohort haemophilic patients cour...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>HIV</td>\n",
       "      <td>HIV3998</td>\n",
       "      <td>evolution definition aids main classifications...</td>\n",
       "      <td>evolution definition aids main classifications...</td>\n",
       "      <td>evolution definition aids main classifications...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>HIV</td>\n",
       "      <td>HIV3999</td>\n",
       "      <td>human immunodeficiency virus glycoproteins gp ...</td>\n",
       "      <td>human immunodeficiency virus glycoproteins gp ...</td>\n",
       "      <td>human immunodeficiency virus glycoproteins gp ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>HIV</td>\n",
       "      <td>HIV4000</td>\n",
       "      <td>predicting progression aids combined usefulnes...</td>\n",
       "      <td>progression aids usefulness cd lymphocyte coun...</td>\n",
       "      <td>progression aids usefulness cd lymphocyte p an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     class document                                               BOAW  \\\n",
       "0      ALZ     ALZ1  reduced amounts immunoreactive somatostatin te...   \n",
       "1      ALZ    ALZ10  diagnostic criteria primary neuronal degenerat...   \n",
       "2      ALZ   ALZ100  cacetylcholine synthesis ccarbon dioxide produ...   \n",
       "3      ALZ  ALZ1000  pattern reading deterioration dementia alzheim...   \n",
       "4      ALZ   ALZ101  cerebral blood flow metabolic rate oxygen gluc...   \n",
       "...    ...      ...                                                ...   \n",
       "3995   HIV  HIV3996  major histocompatibility complex genes influen...   \n",
       "3996   HIV  HIV3997  hiv infection cohort haemophilic patients cour...   \n",
       "3997   HIV  HIV3998  evolution definition aids main classifications...   \n",
       "3998   HIV  HIV3999  human immunodeficiency virus glycoproteins gp ...   \n",
       "3999   HIV  HIV4000  predicting progression aids combined usefulnes...   \n",
       "\n",
       "                                                    BON  \\\n",
       "0     amounts immunoreactive somatostatin temporal c...   \n",
       "1     diagnostic criteria primary neuronal degenerat...   \n",
       "2     cacetylcholine synthesis ccarbon dioxide produ...   \n",
       "3     pattern reading deterioration dementia alzheim...   \n",
       "4     cerebral blood flow metabolic rate oxygen gluc...   \n",
       "...                                                 ...   \n",
       "3995  major histocompatibility complex genes outcome...   \n",
       "3996  hiv infection cohort haemophilic patients cour...   \n",
       "3997  evolution definition aids main classifications...   \n",
       "3998  human immunodeficiency virus glycoproteins gp ...   \n",
       "3999  progression aids usefulness cd lymphocyte coun...   \n",
       "\n",
       "                                                   BONA  \n",
       "0     reduced amounts immunoreactive somatostatin te...  \n",
       "1     diagnostic criteria primary neuronal degenerat...  \n",
       "2     cacetylcholine synthesis ccarbon dioxide produ...  \n",
       "3     pattern deterioration dementia alzheimer type ...  \n",
       "4     cerebral blood flow metabolic rate oxygen gluc...  \n",
       "...                                                 ...  \n",
       "3995  major histocompatibility complex genes influen...  \n",
       "3996  hiv infection cohort haemophilic patients cour...  \n",
       "3997  evolution definition aids main classifications...  \n",
       "3998  human immunodeficiency virus glycoproteins gp ...  \n",
       "3999  progression aids usefulness cd lymphocyte p an...  \n",
       "\n",
       "[4000 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read csv\n",
    "dataFormed = pd.read_csv('pubmed/formed.csv')\n",
    "# get features\n",
    "classes = dataFormed.loc[:, 'class']\n",
    "boaw = dataFormed.loc[:, 'BOAW']\n",
    "bon = dataFormed.loc[:, 'BON']\n",
    "bona = dataFormed.loc[:, 'BONA']\n",
    "dataFormed"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Term Weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'function' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 46\u001b[0m\n\u001b[0;32m     43\u001b[0m       tf[word] \u001b[39m=\u001b[39m val\n\u001b[0;32m     44\u001b[0m     \u001b[39mreturn\u001b[39;00m tfIdf\n\u001b[1;32m---> 46\u001b[0m idfx \u001b[39m=\u001b[39m tf_idf(bona)\n\u001b[0;32m     47\u001b[0m \u001b[39mprint\u001b[39m(idfx)\n\u001b[0;32m     49\u001b[0m \u001b[39m# TF-IDF-ICF\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[23], line 43\u001b[0m, in \u001b[0;36mtf_idf\u001b[1;34m(features)\u001b[0m\n\u001b[0;32m     41\u001b[0m   arr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(df\u001b[39m.\u001b[39mloc[:, word])\n\u001b[0;32m     42\u001b[0m   val \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msum(arr, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m---> 43\u001b[0m   tf[word] \u001b[39m=\u001b[39m val\n\u001b[0;32m     44\u001b[0m \u001b[39mreturn\u001b[39;00m tfIdf\n",
      "\u001b[1;31mTypeError\u001b[0m: 'function' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# TF\n",
    "def tf(features):\n",
    "    # get tf weights\n",
    "    tfVec = CountVectorizer()\n",
    "    result = tfVec.fit_transform(features)\n",
    "\n",
    "    # define weights into dataframe\n",
    "    featureName = tfVec.get_feature_names_out()\n",
    "    featureWeight = result.todense().tolist()\n",
    "    df = pd.DataFrame(featureWeight, columns=featureName)\n",
    "\n",
    "    # counting weights into dictionary\n",
    "    tf = dict.fromkeys(featureName, 0)\n",
    "    for word in featureName:\n",
    "      arr = np.array(df.loc[:, word])\n",
    "      tf[word] = np.sum(arr)\n",
    "    return tf\n",
    "\n",
    "# tfx = tf(bona)\n",
    "# print(tfx)\n",
    "\n",
    "# TF-IDF\n",
    "def tf_idf(features):\n",
    "    # get tf-idf weights\n",
    "    tfIdfVec = TfidfVectorizer()\n",
    "    result = tfIdfVec.fit_transform(features)\n",
    "\n",
    "    # define weights into dataframe\n",
    "    featureName = tfIdfVec.get_feature_names_out()\n",
    "    featureWeight = result.todense().tolist()\n",
    "    df = pd.DataFrame(featureWeight, columns=featureName)\n",
    "    \n",
    "    # counting weights into dictionary\n",
    "    tfIdf = dict.fromkeys(featureName, 0)\n",
    "    for word in featureName:\n",
    "      arr = np.array(df.loc[:, word])\n",
    "      tf[word] = np.sum(arr)\n",
    "    return tfIdf\n",
    "\n",
    "# idfx = tf_idf(bona)\n",
    "# print(idfx)\n",
    "\n",
    "# TF-IDF-ICF\n",
    "def icf(word):\n",
    "  C = []\n",
    "  ct = []\n",
    "\n",
    "  for i in classes:\n",
    "    # count class\n",
    "    if i not in C:\n",
    "      C.append(i)\n",
    "\n",
    "  # for row in \n",
    "    # count class term\n",
    "    if i not in ct:\n",
    "       if \n",
    "  \n",
    "\n",
    "  \n",
    "  for word, val in idfDict.items():\n",
    "      icf = math.log(len(C) / float(val))\n",
    "  \n",
    "  return icf\n",
    "\n",
    "def tf_idf_icf(features):\n",
    "    tfIdf = tf_idf(features)\n",
    "    tfIdfIcf = dict.fromkeys(list(tfIdf.keys()), 0)\n",
    "\n",
    "    for word, val in tfIdf:\n",
    "        tfIdfIcf[word] = val * icf(word)\n",
    "        # break\n",
    "    return tfIdfIcf\n",
    "\n",
    "# icfx = tf_idf_icf(features)\n",
    "# print(icfx)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ab696253bf1cbd9262a120019f89a6af5e719602af9132e0a92b18d085125844"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
